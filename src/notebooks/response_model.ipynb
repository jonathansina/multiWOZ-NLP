{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c12ff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from transformers import T5Tokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import T5ForConditionalGeneration\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from scripts.response.training import train_model\n",
    "from scripts.response.inference import inference_model\n",
    "from scripts.response.preprocessing import ResponseDataset\n",
    "\n",
    "from scripts.global_vars import DEVICE, MAX_LENGTH_RESPONSE, BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e016ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"multi_woz_v22\", trust_remote_code=True)\n",
    "\n",
    "train_data = dataset['train']\n",
    "val_data = dataset['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81914a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dialogues: 100%|██████████| 8437/8437 [00:03<00:00, 2295.16it/s]\n",
      "Processing dialogues: 100%|██████████| 1000/1000 [00:00<00:00, 2137.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action IDs shape: torch.Size([64, 128])\n",
      "Response IDs shape: torch.Size([64, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\n",
    "    legacy=True,\n",
    "    pretrained_model_name_or_path=\"google/t5-efficient-mini\"\n",
    ")\n",
    "\n",
    "train_response_dataset = ResponseDataset(\n",
    "    data=dataset['train'],\n",
    "    tokenizer=tokenizer,\n",
    "    max_output_len=MAX_LENGTH_RESPONSE\n",
    ")\n",
    "\n",
    "valid_response_dataset = ResponseDataset(\n",
    "    data=dataset['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    max_output_len=MAX_LENGTH_RESPONSE\n",
    ")\n",
    "\n",
    "train_loader_response = DataLoader(train_response_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader_response = DataLoader(valid_response_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "batch = next(iter(train_loader_response))\n",
    "print(\"Action IDs shape:\", batch['encoder_input_ids'].shape)\n",
    "print(\"Response IDs shape:\", batch['decoder_input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8b4192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "num_training_steps = len(train_loader_response) * num_epochs\n",
    "num_warmup_steps = num_training_steps // 10\n",
    "\n",
    "response_model = T5ForConditionalGeneration.from_pretrained(\n",
    "    \"google/t5-efficient-mini\"\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = AdamW(\n",
    "    response_model.parameters(),\n",
    "    lr=1e-2,\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1507caf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/888 [00:00<?, ?it/s]Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "Training: 100%|██████████| 888/888 [01:55<00:00,  7.70it/s]\n",
      "Validation: 100%|██████████| 116/116 [00:05<00:00, 20.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training   - Loss: 0.6345\n",
      "Validation - Loss: 0.2137\n",
      "LR: 8.89e-03\n",
      "\n",
      "Epoch 2/5\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 888/888 [01:55<00:00,  7.71it/s]\n",
      "Validation: 100%|██████████| 116/116 [00:05<00:00, 21.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training   - Loss: 0.2229\n",
      "Validation - Loss: 0.1954\n",
      "LR: 6.67e-03\n",
      "\n",
      "Epoch 3/5\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 888/888 [01:54<00:00,  7.74it/s]\n",
      "Validation: 100%|██████████| 116/116 [00:05<00:00, 20.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training   - Loss: 0.2012\n",
      "Validation - Loss: 0.1848\n",
      "LR: 4.44e-03\n",
      "\n",
      "Epoch 4/5\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 888/888 [01:55<00:00,  7.71it/s]\n",
      "Validation: 100%|██████████| 116/116 [00:05<00:00, 21.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training   - Loss: 0.1857\n",
      "Validation - Loss: 0.1763\n",
      "LR: 2.22e-03\n",
      "\n",
      "Epoch 5/5\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 888/888 [01:54<00:00,  7.75it/s]\n",
      "Validation: 100%|██████████| 116/116 [00:05<00:00, 21.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training   - Loss: 0.1708\n",
      "Validation - Loss: 0.1693\n",
      "LR: 0.00e+00\n"
     ]
    }
   ],
   "source": [
    "response_model = train_model(\n",
    "    response_model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    train_loader_response,\n",
    "    valid_loader_response,\n",
    "    num_epochs=num_epochs,\n",
    "    device=DEVICE,\n",
    "    save=\"../../models/multixoz_response_model.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25c046e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Action: [USER]: I'm looking for a train leaving on Wednesday that's going to Cambridge. [ACTION]: Train-Request(departure=?)\n",
      "Generated Response: Where will you be departing from?\n",
      "True Response: Okay, where are you departing?\n"
     ]
    }
   ],
   "source": [
    "index = 105\n",
    "inputs = valid_response_dataset.actions[index]\n",
    "\n",
    "generated_output = inference_model(\n",
    "    response_model,\n",
    "    tokenizer,\n",
    "    inputs,\n",
    "    MAX_LENGTH_RESPONSE,\n",
    "    DEVICE\n",
    ")\n",
    "\n",
    "print(\"User Action:\", inputs)\n",
    "print(\"Generated Response:\", generated_output)\n",
    "print(\"True Response:\", valid_response_dataset.responses[index])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
