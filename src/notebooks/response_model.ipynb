{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c12ff90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from torch.optim import AdamW\n",
    "from transformers import T5Tokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import T5ForConditionalGeneration\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from scripts.response.training import train_model\n",
    "from scripts.response.inference import inference_model\n",
    "from scripts.response.preprocessing import ResponseDataset\n",
    "\n",
    "from scripts.global_vars import DEVICE, MAX_LENGTH, BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1e016ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"multi_woz_v22\", trust_remote_code=True)\n",
    "\n",
    "train_data = dataset['train']\n",
    "val_data = dataset['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81914a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing dialogues: 100%|██████████| 8437/8437 [00:03<00:00, 2227.64it/s]\n",
      "Processing dialogues: 100%|██████████| 1000/1000 [00:00<00:00, 2136.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action IDs shape: torch.Size([64, 128])\n",
      "Response IDs shape: torch.Size([64, 128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\n",
    "    legacy=True,\n",
    "    pretrained_model_name_or_path=\"google/t5-efficient-mini\"\n",
    ")\n",
    "\n",
    "train_response_dataset = ResponseDataset(\n",
    "    data=dataset['train'],\n",
    "    tokenizer=tokenizer,\n",
    "    max_output_len=MAX_LENGTH\n",
    ")\n",
    "\n",
    "valid_response_dataset = ResponseDataset(\n",
    "    data=dataset['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    max_output_len=MAX_LENGTH\n",
    ")\n",
    "\n",
    "train_loader_response = DataLoader(train_response_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader_response = DataLoader(valid_response_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "batch = next(iter(train_loader_response))\n",
    "print(\"Action IDs shape:\", batch['encoder_input_ids'].shape)\n",
    "print(\"Response IDs shape:\", batch['decoder_input_ids'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8b4192f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "num_training_steps = len(train_loader_response) * num_epochs\n",
    "num_warmup_steps = num_training_steps // 10\n",
    "\n",
    "response_model = T5ForConditionalGeneration.from_pretrained(\n",
    "    \"google/t5-efficient-mini\"\n",
    ").to(DEVICE)\n",
    "\n",
    "optimizer = AdamW(\n",
    "    response_model.parameters(),\n",
    "    lr=1e-3,\n",
    "    eps=1e-8\n",
    ")\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1507caf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/888 [00:00<?, ?it/s]Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "Training:  79%|███████▉  | 703/888 [01:30<00:24,  7.61it/s]"
     ]
    }
   ],
   "source": [
    "response_model = train_model(\n",
    "    response_model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    train_loader_response,\n",
    "    val_loader_response,\n",
    "    num_epochs=num_epochs,\n",
    "    device=DEVICE,\n",
    "    save=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c046e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I was able to book you a table for you. Your reference number is FRGZWQL2 . Is there anything else I can help you with?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_model(\n",
    "    response_model,\n",
    "    tokenizer,\n",
    "    train_response_dataset.actions[4],\n",
    "    MAX_LENGTH,\n",
    "    DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78273ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Booking-Book(ref=FRGZWQL2) | general-reqmore(none=none)',\n",
       " 'Your booking was successful. Your reference number is FRGZWQL2 . May I help you further?')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_response_dataset.actions[4], train_response_dataset.responses[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8a975a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
